
from snakemake.utils import min_version
min_version("6.0")

import importlib
retrieve_databundle_light = importlib.import_module("subworkflows.pypsa-earth.scripts.retrieve_databundle_light")
# helpers = importlib.import_module("subworkflows.pypsa-earth.scripts._helpers")

from snakemake.remote.HTTP import RemoteProvider as HTTPRemoteProvider
from retrieve_databundle_light import datafiles_retrivedatabundle

HTTP = HTTPRemoteProvider()

# -------------------------- Imports and Parameters -------------------------- #

from os.path import normpath

FIGURES_SINGLE = [
    "capacity_map",
    "capacity_bar",
    "operation_map",
    "operation_bar",
    "operation_area",
    "cost_bar",
]

# --------------------------- Workflow constraints --------------------------- #

localrules:
    # dag,
    # report,
    clean,

wildcard_constraints:
    interconnect="usa|texas|western|eastern",
    simpl="[a-zA-Z0-9]*|all",
    clusters="[0-9]+m?|all",
    ll="(v|c)([0-9\.]+|opt|all)|all",
    opts="[-+a-zA-Z0-9\.]*",


# -------------------------- Config and Subworkflows ------------------------- #

# Merge subworkflow configs and main config
configfile: "config/config.yaml"
configfile: "config/config.cluster.yaml"

ATLITE_NPROCESSES = config["atlite"].get("nprocesses", 4)

run = config.get("run", {})
RDIR = run["name"] + "/" if run.get("name") else ""
CDIR = RDIR if not run.get("shared_cutouts") else ""

LOGS = "logs/" + RDIR
BENCHMARKS = "benchmarks/" + RDIR
RESOURCES = "resources/" + RDIR if not run.get("shared_resources") else "resources/"
RESULTS = "results/" + RDIR

# ----------------------------------- Rules ---------------------------------- #


rule all:
    input:
        expand(
            "results/{interconnect}/figures/elec_s_{clusters}_ec_l{ll}_{opts}_{figure}.pdf",
            **config["scenarios"]["all"],
            figure=FIGURES_SINGLE
        ),

rule test:
    input:
        expand(
            "results/{interconnect}/figures/elec_s_{clusters}_ec_l{ll}_{opts}_{figure}.pdf",
            **config["scenarios"]["test"],
            figure=FIGURES_SINGLE
        ),


################# ----------- Rules to Retrieve Data ---------- #################

DATAFILES = [
    "bus.csv",
    "sub.csv",
    "bus2sub.csv",
    "branch.csv",
    "dcline.csv",
    "demand.csv",
    "plant.csv",
    "solar.csv",
    "wind.csv",
    "hydro.csv",
    "zone.csv",
]

rule retrieve_data_from_zenodo:
    output:
        expand("data/base_grid/{file}", file=DATAFILES),
    log:
        "logs/retrieve_data_from_zenodo.log",
    script:
        "scripts/retrieve_data_from_zenodo.py"

rule retrieve_forecast_data:
    output:
        ads_2032 = directory('resources/WECC_ADS/downloads/2032/Public Data/Hourly Profiles in CSV format'),
        ads_2030 = directory('resources/WECC_ADS/downloads/2030/WECC 2030 ADS PCM 2020-12-16 (V1.5) Public Data/CSV Shape Files'),
    log:
        "logs/retrieve_forecast_data.log",
    script:
        "scripts/retrieve_forecast_data.py"        

DATAFILES_DMD = [
    "EIA_DMD_2015.csv",
    "EIA_DMD_2016.csv",
    "EIA_DMD_2017.csv",
    "EIA_DMD_2018.csv",
    "EIA_DMD_2019.csv",
    "EIA_DMD_2020.csv",
    "EIA_DMD_2021.csv",
    "EIA_DMD_2022.csv",
    "EIA_DMD_2023.csv",
    ]

rule retrieve_eia_data:
    output:
        expand("resources/eia/{file}", file=DATAFILES_DMD),
    log:
        "logs/retrieve_historical_load_data.log",
    script:
        "scripts/retrieve_historical_load_data.py"


rule retrieve_ship_raster:
    input:
        HTTP.remote(
            "https://zenodo.org/record/6953563/files/shipdensity_global.zip",
            keep_local=True,
            static=True,
        ),
    output:
        "data/shipdensity_global.zip",
    log:
        LOGS + "retrieve_ship_raster.log",
    resources:
        mem_mb=5000,
    retries: 2
    run:
        move(input[0], output[0])

if config["enable"].get("retrieve_databundle", True):
    datafiles = [
        "ch_cantons.csv",
        "je-e-21.03.02.xls",
        "eez/World_EEZ_v8_2014.shp",
        "hydro_capacities.csv",
        "naturalearth/ne_10m_admin_0_countries.shp",
        "nama_10r_3popgdp.tsv.gz",
        "nama_10r_3gdp.tsv.gz",
        "corine/g250_clc06_V18_5.tif",
    ]

    if not config.get("tutorial", False):
        datafiles.extend(["natura/Natura2000_end2015.shp", "GEBCO_2014_2D.nc"])

    rule retrieve_databundle:
        output:
            expand("data/pypsa-eur/{file}", file=datafiles),
        log:
            LOGS + "retrieve_databundle.log",
        resources:
            mem_mb=1000,
        retries: 2
        conda:
            "../envs/environment.yaml"
        script:
            "../scripts/retrieve_databundle.py"

    rule retrieve_databundle_light:
        output:  #expand(directory('{file}') if isdir('{file}') else '{file}', file=datafiles)
            expand("pypsa_earth_{file}", file=datafiles_retrivedatabundle(config)),
            directory("data/landcover"),
        log:
            "logs/" + RDIR + "retrieve_databundle.log",
        benchmark:
            "benchmarks/" + RDIR + "retrieve_databundle_light"
        script:
            "subworkflows/pypsa-earth/scripts/retrieve_databundle_light.py"


if config["enable"].get("retrieve_cutout", True):

    rule retrieve_cutout:
        input:
            HTTP.remote(
                "zenodo.org/record/8136996/files/cutout_western_{cutout}.nc"
                ,static=True),
        output:
            protected("cutouts/" + CDIR + "cutout_{interconnect}_{cutout}.nc"),
        log:
            "logs/" + CDIR + "retrieve_cutout_{interconnect}_{cutout}.log",
        resources:
            mem_mb=5000,
        retries: 2
        run:
            move(input[0], output[0])
####"https://zenodo.org/record/8136996/files/cutout_western_ERA5_2019.nc",

if config["enable"].get("build_natura_raster", False):

    rule build_natura_raster:
        input:
            # natura=ancient("data/bundle/natura/Natura2000_end2015.shp"),
            cutouts=expand("cutouts/" + CDIR + "cutout_western_{cutouts}.nc", **config["atlite"]),
        output:
            RESOURCES + "natura.tiff",
        resources:
            mem_mb=5000,
        log:
            LOGS + "build_natura_raster.log",
        conda:
            "../envs/environment.yaml"
        script:
            "../scripts/build_natura_raster.py"

################# ----------- Rules to Build Network ---------- #################

rule build_shapes:
    params:
        source_states_shapes="admin_1_states_provinces",
        source_offshore_shapes=config["offshore_shape"],
        buffer_distance=200000,
        balancing_authorities=config["balancing_authorities"],
    input:
        zone="data/base_grid/zone.csv",
    output:
        country_shapes="resources/{interconnect}/country_shapes.geojson",
        onshore_shapes="resources/{interconnect}/onshore_shapes.geojson",
        offshore_shapes="resources/{interconnect}/offshore_shapes.geojson",
    log:
        "logs/build_shapes_{interconnect}.log",
    threads: 1
    resources:
        mem_mb=1000,
    script:
        "scripts/build_shapes.py"

rule build_base_network:
    input:
        buses="data/base_grid/bus.csv",
        lines="data/base_grid/branch.csv",
        links="data/base_grid/dcline.csv",
        bus2sub="data/base_grid/bus2sub.csv",
        sub="data/base_grid/sub.csv",
        onshore_shapes="resources/{interconnect}/onshore_shapes.geojson",
        offshore_shapes="resources/{interconnect}/offshore_shapes.geojson",
    output:
        bus2sub="data/base_grid/{interconnect}/bus2sub.csv",
        sub="data/base_grid/{interconnect}/sub.csv",
        network="resources/{interconnect}/elec_base_network.nc",
    log:
        "logs/create_network/{interconnect}.log",
    threads: 4
    resources:
        mem=500,
    script:
        "scripts/build_base_network.py"

rule build_load_data:
    input:
        network="resources/{interconnect}/elec_base_network.nc",
        demand_breakthrough_2016="data/base_grid/demand.csv",
        ads_2032 = 'resources/WECC_ADS/downloads/2032/Public Data/Hourly Profiles in CSV format',
        ads_2030 = 'resources/WECC_ADS/downloads/2030/WECC 2030 ADS PCM 2020-12-16 (V1.5) Public Data/CSV Shape Files',
        eia = expand("resources/eia/{file}", file=DATAFILES_DMD),
        tech_costs="repo_data/pypsa_eur_costs.csv",
    output:
        network="resources/{interconnect}/elec_base_network_l.nc",
    log:
        "logs/build_load_data/{interconnect}.log",
    script:
        "scripts/build_load_data.py"

        
# if config["enable"].get("build_cutout", False):
#     rule build_cutout:
#         input:
#             onshore_shapes="resources/{interconnect}/country_shapes.geojson",
#             offshore_shapes="resources/{interconnect}/offshore_shapes.geojson",
#         output:
#             cutout = "resources/{interconnect}/cutout_{interconnect}.nc",
#         script:
#             "scripts/build_cutout_earth.py"


rule build_ship_raster:
    input:
        ship_density="data/shipdensity_global.zip",
        cutouts=expand(
            "cutouts/" + CDIR + "cutout_western_{cutout}.nc",
            cutout=[
                config["renewable"][carrier]["cutout"]
                for carrier in config["electricity"]["renewable_carriers"]
            ],
        ),
    output:
        RESOURCES + "{interconnect}/shipdensity_raster.tif",
    log:
        LOGS + "{interconnect}/build_ship_raster.log",
    resources:
        mem_mb=5000,
    benchmark:
        BENCHMARKS + "{interconnect}/build_ship_raster"
    script:
        "subworkflows/pypsa-eur/scripts/build_ship_raster.py"


rule build_renewable_profiles:
    params:
        renewable=config["renewable"],
    input:
        base_network=RESOURCES + "{interconnect}/elec_base_network_l.nc",
        # corine=ancient("data/bundle/corine/g250_clc06_V18_5.tif"),
        natura=lambda w: (
            RESOURCES + "natura.tiff"
            if config["renewable"][w.technology]["natura"]
            else []
        ),
        # gebco=ancient(
        #     lambda w: (
        #         "data/bundle/GEBCO_2014_2D.nc"
        #         if config["renewable"][w.technology].get("max_depth")
        #         else []
        #     )
        # ),
        ship_density=lambda w: (
            RESOURCES + "{interconnect}/shipdensity_raster.tif"
            if "ship_threshold" in config["renewable"][w.technology].keys()
            else []
        ),
        country_shapes=RESOURCES + "{interconnect}/country_shapes.geojson",
        offshore_shapes=RESOURCES + "{interconnect}/offshore_shapes.geojson",
        regions=lambda w: (
            RESOURCES + "{interconnect}/regions_onshore_s.geojson"
            if w.technology in ("onwind", "solar")
            else RESOURCES + "{interconnect}/regions_offshore_S.geojson"
        ),
        cutout=lambda w: "cutouts/"
        + CDIR + "cutout_{interconnect}_"
        + config["renewable"][w.technology]["cutout"]
        + ".nc",
    output:
        profile=RESOURCES + "{interconnect}/profile_{technology}.nc",
    log:
        LOGS + "{interconnect}/build_renewable_profile_{technology}.log",
    benchmark:
        BENCHMARKS + "{interconnect}/build_renewable_profiles_{technology}"
    threads: ATLITE_NPROCESSES
    resources:
        mem_mb=ATLITE_NPROCESSES * 5000,
    wildcard_constraints:
        technology="(?!hydro).*",  # Any technology other than hydro
    conda:
        "../envs/environment.yaml"
    script:
        "subworkflows/pypsa-eur/scripts/build_renewable_profiles.py"


rule add_electricity:
    params:
        length_factor=config["lines"]["length_factor"],
        scaling_factor=config["load"]["scaling_factor"],
        countries=config["countries"],
        renewable=config["renewable"],
        electricity=config["electricity"],
        conventional=config.get("conventional", {}),
        costs=config["costs"],
    input:
        **{
            f"profile_{tech}": RESOURCES + "{interconnect}" + f"/profile_{tech}.nc"
            for tech in config["electricity"]["renewable_carriers"]
        },
        # **{
        #     f"conventional_{carrier}_{attr}": fn
        #     for carrier, d in config.get("conventional", {None: {}}).items()
        #     for attr, fn in d.items()
        #     if str(fn).startswith("data/")
        # },
        base_network=RESOURCES + "{interconnect}/elec_base_network_l.nc",
        tech_costs="repo_data/pypsa_eur_costs.csv",
        regions=RESOURCES + "{interconnect}/regions_onshore_s.geojson",
        powerplants="data/base_grid/plant.csv",
        # hydro_capacities=ancient("data/bundle/hydro_capacities.csv"),
        # geth_hydro_capacities="data/geth2015_hydro_capacities.csv",
        # load=RESOURCES + "load.csv",
    output:
        RESOURCES + "{interconnect}/elec_base_network_l_pp.nc",
    log:
        LOGS + "{interconnect}_add_electricity.log",
    benchmark:
        BENCHMARKS + "{interconnect}_add_electricity"
    threads: 1
    resources:
        mem_mb=5000,
    conda:
        "../envs/environment.yaml"
    script:
        "../scripts/add_electricity.py"

# rule build_powerplants:
#     input:
#         network="resources/{interconnect}/elec_base_network_l.nc",
#         plants="data/base_grid/plant.csv",
#         wind="data/base_grid/wind.csv",
#         solar="data/base_grid/solar.csv",
#         hydro="data/base_grid/hydro.csv",
#         tech_costs="repo_data/pypsa_eur_costs.csv",
#         cutout="resources/{interconnect}/cutout_{interconnect}_ERA5.nc"
#     output:
#         network="resources/{interconnect}/elec_base_network_l_pp.nc",
#     log:
#         "logs/create_network/{interconnect}.log",
#     threads: 4
#     resources:
#         mem=500,
#     script:
#         "scripts/build_powerplants.py"

################# ----------- Rules to Aggregate & Simplify Network ---------- #################
rule simplify_network:
    input:
        bus2sub="data/base_grid/{interconnect}/bus2sub.csv",
        sub="data/base_grid/{interconnect}/sub.csv",
        network= RESOURCES + "{interconnect}/elec_base_network_l_pp.nc",
    output:
        network="resources/{interconnect}/elec_s.nc",
    log:
        "logs/simplify_network/{interconnect}/elec_s.log",
    threads: 4
    resources:
        mem=500,
    script:
        "scripts/simplify_network.py"

rule build_bus_regions:
    params:
        balancing_authorities=config["balancing_authorities"],
    input:
        country_shapes="resources/{interconnect}/country_shapes.geojson",
        ba_region_shapes="resources/{interconnect}/onshore_shapes.geojson",
        offshore_shapes="resources/{interconnect}/offshore_shapes.geojson",
        base_network="resources/{interconnect}/elec_s.nc",
    output:
        regions_onshore="resources/{interconnect}/regions_onshore_s.geojson",
        regions_offshore="resources/{interconnect}/regions_offshore_s.geojson",
        network="resources/{interconnect}/elec_ss.nc",
    log:
        "logs/{interconnect}/build_bus_regions_s.log",
    threads: 1
    resources:
        mem_mb=1000,
    script:
        "scripts/build_bus_regions.py"


rule cluster_network:
    input:
        network="resources/{interconnect}/elec_ss.nc",
        regions_onshore="resources/{interconnect}/regions_onshore_s.geojson",
        regions_offshore="resources/{interconnect}/regions_offshore_s.geojson",
        busmap="data/base_grid/{interconnect}/bus2sub.csv",
        custom_busmap=(
            "data/{interconnect}/custom_busmap_{clusters}.csv"
            if config["enable"].get("custom_busmap", False)
            else []
        ),
        tech_costs="repo_data/pypsa_eur_costs.csv",
    output:
        network="resources/{interconnect}/elec_s_{clusters}.nc",
        regions_onshore="resources/{interconnect}/regions_onshore_s_{clusters}.geojson",
        regions_offshore="resources/{interconnect}/regions_offshore_s_{clusters}.geojson",
        busmap="resources/{interconnect}/busmap_s_{clusters}.csv",
        linemap="resources/{interconnect}/linemap_s_{clusters}.csv",
    log:
        "logs/cluster_network/{interconnect}/elec_s_{clusters}.log",
    benchmark:
        "benchmarks/cluster_network/{interconnect}/elec_s_{clusters}"
    threads: 1
    resources:
        mem_mb=6000,
    script:
        "scripts/cluster_network_eur.py"


################# ----------- Rules to Optimize ---------- #################


rule add_extra_components:
    input:
        network="resources/{interconnect}/elec_s_{clusters}.nc",
        tech_costs="repo_data/pypsa_eur_costs.csv",
    output:
        "resources/{interconnect}/elec_s_{clusters}_ec.nc",
    log:
        "logs/add_extra_components/{interconnect}/elec_s_{clusters}_ec.log",
    threads: 4
    resources:
        mem=500,
    script:
        "scripts/add_extra_components.py"

rule prepare_network:
    input:
        network="resources/{interconnect}/elec_s_{clusters}_ec.nc",
        tech_costs="repo_data/pypsa_eur_costs.csv",
    output:
        "resources/{interconnect}/elec_s_{clusters}_ec_l{ll}_{opts}.nc",
    log:
        solver="logs/prepare_network/{interconnect}/elec_s_{clusters}_ec_l{ll}_{opts}.log",
    threads: 4
    resources:
        mem=5000,
    log:
        "logs/prepare_network",
    script:
        "scripts/prepare_network.py"

def memory(w):
    factor = 3.0
    for o in w.opts.split("-"):
        m = re.match(r"^(\d+)h$", o, re.IGNORECASE)
        if m is not None:
            factor /= int(m.group(1))
            break
    for o in w.opts.split("-"):
        m = re.match(r"^(\d+)seg$", o, re.IGNORECASE)
        if m is not None:
            factor *= int(m.group(1)) / 8760
            break
    if w.clusters.endswith("m"):
        return int(factor * (18000 + 180 * int(w.clusters[:-1])))
    elif w.clusters == "all":
        return int(factor * (18000 + 180 * 4000))
    else:
        return int(factor * (10000 + 195 * int(w.clusters)))


rule solve_network:
    input:
        "resources/{interconnect}/elec_s_{clusters}_ec_l{ll}_{opts}.nc",
    output:
        "results/{interconnect}/networks/elec_s_{clusters}_ec_l{ll}_{opts}.nc",
    log:
        solver=normpath(
            "logs/solve_network/{interconnect}/elec_s_{clusters}_ec_l{ll}_{opts}_solver.log"
        ),
        python="logs/solve_network/{interconnect}/elec_s_{clusters}_ec_l{ll}_{opts}_python.log",
        memory="logs/solve_network/{interconnect}/elec_s_{clusters}_ec_l{ll}_{opts}_memory.log",
    benchmark:
        "benchmarks/solve_network/{interconnect}/elec_s_{clusters}_ec_l{ll}_{opts}"
    threads: 8
    resources:
        mem_mb=memory,
    script:
        "scripts/solve_network.py"


rule plot_figures_single:
    input:
        network="results/{interconnect}/networks/elec_s_{clusters}_ec_l{ll}_{opts}.nc",
        regions_onshore="resources/{interconnect}/regions_onshore_s_{clusters}.geojson",
        regions_offshore="resources/{interconnect}/regions_offshore_s_{clusters}.geojson",
    output:
        **{
            fig: "results/{interconnect}/figures/elec_s_{clusters}_ec_l{ll}_{opts}_%s.pdf"
            % fig
            for fig in FIGURES_SINGLE
        },
    notebook:
        "notebooks/plot-results.py.ipynb"

rule sync:
    params:
        cluster=config["cluster"],
    shell:
        """
        rsync -uvarh --no-g --ignore-missing-args --files-from=.sync-send . {params.cluster}
        rsync -uvarh --no-g --ignore-missing-args --files-from=.sync-receive {params.cluster} .
        """

rule report:
    message:
        "Compile report."
    input:
        tex="report/report.tex",
        bib="report/references.bib",
    output:
        "report/report.pdf",
    shell:
        """
        pdflatex {input.tex}
        bibtex {input.bib})
        pdflatex {input.tex}
        pdflatex {input.tex}
        """

# Create DAG with- snakemake --dag results/western/networks/elec_s_40_ec_lvopt_Co2L1.0.nc -F | sed -n "/digraph/,/}/p" | dot -Tpng -o results/workflow.png
rule dag:
    message:
        "Plotting dependency graph of the workflow."
    output:
        dot="resources/dag.dot",
        pdf="resources/dag.pdf",
    shell:
        """
        snakemake --rulegraph > {output.dot}
        dot -Tpdf -o {output.pdf} {output.dot}
        """

rule clean:
    message:
        "Remove all build results but keep downloaded data."
    run:
        import shutil

        shutil.rmtree("resources", ignore_errors=True)
        shutil.rmtree("results", ignore_errors=True)
        print("Data downloaded to data/ has not been cleaned.")
