# Copyright 2021-2022 Martha Frysztacki (KIT), Fabian Hofmann (TUB)

# -------------------------- Imports and Parameters -------------------------- #

from os.path import normpath

PYPSAEUR = "workflow/subworkflows/pypsa-eur/"
FIGURES_SINGLE = [
    "capacity_map",
    "capacity_bar",
    "operation_map",
    "operation_bar",
    "operation_area",
    "cost_bar",
]

# --------------------------- Workflow constraints --------------------------- #


localrules:
    report,
    clean,


wildcard_constraints:
    interconnect="usa|texas|western|eastern",
    simpl="[a-zA-Z0-9]*|all",
    clusters="[0-9]+m?|all",
    ll="(v|c)([0-9\.]+|opt|all)|all",
    opts="[-+a-zA-Z0-9\.]*",


# -------------------------- Config and Subworkflows ------------------------- #


# Merge subworkflow configs and main config
configfile: "config/config.pypsa-eur.yaml"
configfile: "config/config.yaml"
configfile: "config/config.cluster.yaml"


subworkflow pypsaeur:
    workdir:
        "subworkflows/pypsa-eur"
    snakefile:
        "subworkflows/pypsa-eur/Snakefile"


# ----------------------------------- Rules ---------------------------------- #


rule all:
    input:
        expand(
            "results/{interconnect}/figures/elec_s_{clusters}_ec_l{ll}_{opts}_{figure}.pdf",
            **config["scenarios"]["all"],
            figure=FIGURES_SINGLE
        ),


rule test:
    input:
        expand(
            "results/{interconnect}/figures/elec_s_{clusters}_ec_l{ll}_{opts}_{figure}.pdf",
            **config["scenarios"]["test"],
            figure=FIGURES_SINGLE
        ),


if not config["zenodo_repository"]["use"]: #Creating network from powersimdata
    rule create_network:
        input:
            tech_costs=pypsaeur("resources/costs.csv"),
        output:
            bus2sub="data/base_grid/{interconnect}/bus2sub.csv",
            sub="data/base_grid/{interconnect}/sub.csv",
            network="resources/{interconnect}/elec.nc",
        log:
            "logs/create_network/{interconnect}.log",
        threads: 4
        resources:
            mem=500,
        script:
            "scripts/create_network_from_powersimdata.py"


else:                            #Creating network from zenodo

    DATAFILES = [
        "bus.csv",
        "sub.csv",
        "bus2sub.csv",
        "branch.csv",
        "dcline.csv",
        "demand.csv",
        "plant.csv",
        "solar.csv",
        "wind.csv",
        "hydro.csv",
    ]

    rule retrieve_data_from_zenodo:
        output:
            expand("data/base_grid/{file}", file=DATAFILES),
        log:
            "logs/retrieve_data_from_zenodo.log",
        script:
            "scripts/retrieve_data_from_zenodo.py"

    rule create_network:
        input:
            buses="data/base_grid/bus.csv",
            lines="data/base_grid/branch.csv",
            links="data/base_grid/dcline.csv",
            plants="data/base_grid/plant.csv",
            wind="data/base_grid/wind.csv",
            solar="data/base_grid/solar.csv",
            hydro="data/base_grid/hydro.csv",
            demand="data/base_grid/demand.csv",
            bus2sub="data/base_grid/bus2sub.csv",
            sub="data/base_grid/sub.csv",
            tech_costs=pypsaeur("resources/costs.csv"),
        output:
            bus2sub="data/base_grid/{interconnect}/bus2sub.csv",
            sub="data/base_grid/{interconnect}/sub.csv",
            network="resources/{interconnect}/elec.nc",
        log:
            "logs/create_network/{interconnect}.log",
        threads: 4
        resources:
            mem=500,
        script:
            "scripts/create_network_from_zenodo.py"


if config["offshore"] == "weathergov":
    rule build_shapes:
        params:
            source_states_shapes="admin_1_states_provinces",
            source_offshore_shapes=config["offshore_weathergov"]["path"],
            buffer_distance=200000,
        input:
            zone="data/base_grid/zone.csv",
        output:
            country_shapes="resources/{interconnect}/country_shapes.geojson",
            state_shapes="resources/{interconnect}/state_shapes.geojson",
            offshore_shapes="resources/{interconnect}/offshore_shapes.geojson",
        log:
            "logs/build_shapes_{interconnect}.log",
        threads: 1
        resources:
            mem_mb=1000,
        script:
            "scripts/build_shapes.py"
elif config["offshore"] == "nrel":
    rule build_shapes:
        params:
            source_states_shapes="admin_1_states_provinces",
            source_offshore_shapes=config["offshore_nrel"]["path"],
            buffer_distance=20000,
        input:
            zone="data/base_grid/zone.csv",
        output:
            country_shapes="resources/{interconnect}/country_shapes.geojson",
            state_shapes="resources/{interconnect}/state_shapes.geojson",
            offshore_shapes="resources/{interconnect}/offshore_shapes.geojson",
        log:
            "logs/build_shapes_{interconnect}.log",
        threads: 1
        resources:
            mem_mb=1000,
        script:
            "scripts/build_shapes.py"
else:
    rule build_shapes:
        params:
            source_states_shapes="admin_1_states_provinces",
            source_offshore_shapes=config["offshore_ca"]["path"],
            buffer_distance=200000,
        input:
            zone="data/base_grid/zone.csv",
        output:
            country_shapes="resources/{interconnect}/country_shapes.geojson",
            state_shapes="resources/{interconnect}/state_shapes.geojson",
            offshore_shapes="resources/{interconnect}/offshore_shapes.geojson",
        log:
            "logs/build_shapes_{interconnect}.log",
        threads: 1
        resources:
            mem_mb=1000,
        script:
            "scripts/build_shapes.py"


rule build_bus_regions:
    params:
        use_state_shapes= config["use_state_shapes"],
    input:
        country_shapes="resources/{interconnect}/country_shapes.geojson",
        state_shapes="resources/{interconnect}/state_shapes.geojson",
        offshore_shapes="resources/{interconnect}/offshore_shapes.geojson",
        base_network="resources/{interconnect}/elec_s.nc",
    output:
        regions_onshore="resources/{interconnect}/regions_onshore_s.geojson",
        regions_offshore="resources/{interconnect}/regions_offshore_s.geojson",
        network="resources/{interconnect}/elec_ss.nc",
    log:
        "logs/{interconnect}/build_bus_regions_s.log",
    threads: 1
    resources:
        mem_mb=1000,
    script:
        "scripts/build_bus_regions.py"


rule simplify_network:
    input:
        bus2sub="data/base_grid/{interconnect}/bus2sub.csv",
        sub="data/base_grid/{interconnect}/sub.csv",
        network="resources/{interconnect}/elec.nc",
    output:
        network="resources/{interconnect}/elec_s.nc",
    log:
        "logs/simplify_network/{interconnect}/elec_s.log",
    threads: 4
    resources:
        mem=500,
    script:
        "scripts/simplify_network.py"


rule cluster_network:
    input:
        network="resources/{interconnect}/elec_ss.nc",
        regions_onshore="resources/{interconnect}/regions_onshore_s.geojson",
        regions_offshore="resources/{interconnect}/regions_offshore_s.geojson",
        busmap="data/base_grid/{interconnect}/bus2sub.csv",
        custom_busmap=(
            "data/{interconnect}/custom_busmap_{clusters}.csv"
            if config["enable"].get("custom_busmap", False)
            else []
        ),
        tech_costs=pypsaeur("resources/costs.csv"),
    output:
        network="resources/{interconnect}/elec_s_{clusters}.nc",
        regions_onshore="resources/{interconnect}/regions_onshore_s_{clusters}.geojson",
        regions_offshore="resources/{interconnect}/regions_offshore_s_{clusters}.geojson",
        busmap="resources/{interconnect}/busmap_s_{clusters}.csv",
        linemap="resources/{interconnect}/linemap_s_{clusters}.csv",
    log:
        "logs/cluster_network/{interconnect}/elec_s_{clusters}.log",
    benchmark:
        "benchmarks/cluster_network/{interconnect}/elec_s_{clusters}"
    threads: 1
    resources:
        mem_mb=6000,
    script:
        pypsaeur("scripts/cluster_network.py")


rule add_extra_components:
    input:
        network="resources/{interconnect}/elec_s_{clusters}.nc",
        tech_costs=pypsaeur("resources/costs.csv"),
    output:
        "resources/{interconnect}/elec_s_{clusters}_ec.nc",
    log:
        "logs/add_extra_components/{interconnect}/elec_s_{clusters}_ec.log",
    threads: 4
    resources:
        mem=500,
    script:
        pypsaeur("scripts/add_extra_components.py")


rule prepare_network:
    input:
        network="resources/{interconnect}/elec_s_{clusters}_ec.nc",
        tech_costs=pypsaeur("resources/costs.csv"),
    output:
        "resources/{interconnect}/elec_s_{clusters}_ec_l{ll}_{opts}.nc",
    log:
        solver="logs/prepare_network/{interconnect}/elec_s_{clusters}_ec_l{ll}_{opts}.log",
    threads: 4
    resources:
        mem=5000,
    log:
        "logs/prepare_network",
    script:
        pypsaeur("scripts/prepare_network.py")


def memory(w):
    factor = 3.0
    for o in w.opts.split("-"):
        m = re.match(r"^(\d+)h$", o, re.IGNORECASE)
        if m is not None:
            factor /= int(m.group(1))
            break
    for o in w.opts.split("-"):
        m = re.match(r"^(\d+)seg$", o, re.IGNORECASE)
        if m is not None:
            factor *= int(m.group(1)) / 8760
            break
    if w.clusters.endswith("m"):
        return int(factor * (18000 + 180 * int(w.clusters[:-1])))
    elif w.clusters == "all":
        return int(factor * (18000 + 180 * 4000))
    else:
        return int(factor * (10000 + 195 * int(w.clusters)))


rule solve_network:
    input:
        "resources/{interconnect}/elec_s_{clusters}_ec_l{ll}_{opts}.nc",
    output:
        "results/{interconnect}/networks/elec_s_{clusters}_ec_l{ll}_{opts}.nc",
    log:
        solver=normpath(
            "logs/solve_network/{interconnect}/elec_s_{clusters}_ec_l{ll}_{opts}_solver.log"
        ),
        python="logs/solve_network/{interconnect}/elec_s_{clusters}_ec_l{ll}_{opts}_python.log",
        memory="logs/solve_network/{interconnect}/elec_s_{clusters}_ec_l{ll}_{opts}_memory.log",
    benchmark:
        "benchmarks/solve_network/{interconnect}/elec_s_{clusters}_ec_l{ll}_{opts}"
    threads: 8
    resources:
        mem_mb=memory,
    script:
        pypsaeur("scripts/solve_network.py")


rule plot_figures_single:
    input:
        network="results/{interconnect}/networks/elec_s_{clusters}_ec_l{ll}_{opts}.nc",
        regions_onshore="resources/{interconnect}/regions_onshore_s_{clusters}.geojson",
        regions_offshore="resources/{interconnect}/regions_offshore_s_{clusters}.geojson",
    output:
        **{
            fig: "results/{interconnect}/figures/elec_s_{clusters}_ec_l{ll}_{opts}_%s.pdf"
            % fig
            for fig in FIGURES_SINGLE
        },
    notebook:
        "notebooks/plot-results.py.ipynb"


rule sync:
    params:
        cluster=config["cluster"],
    shell:
        """
        rsync -uvarh --no-g --ignore-missing-args --files-from=.sync-send . {params.cluster}
        rsync -uvarh --no-g --ignore-missing-args --files-from=.sync-receive {params.cluster} .
        """


rule report:
    message:
        "Compile report."
    input:
        tex="report/report.tex",
        bib="report/references.bib",
    output:
        "report/report.pdf",
    shell:
        """
        pdflatex {input.tex}
        bibtex {input.bib})
        pdflatex {input.tex}
        pdflatex {input.tex}
        """


rule dag:
    message:
        "Plot dependency graph of the workflow."
    output:
        dot="resources/dag.dot",
        pdf="resources/dag.pdf",
    shell:
        """
        snakemake --rulegraph > {output.dot}
        dot -Tpdf -o {output.pdf} {output.dot}
        """


rule clean:
    message:
        "Remove all build results but keep downloaded data."
    run:
        import shutil

        shutil.rmtree("resources", ignore_errors=True)
        shutil.rmtree("results", ignore_errors=True)
        print("Data downloaded to data/ has not been cleaned.")
