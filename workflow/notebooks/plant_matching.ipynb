{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INITIALIZE THE DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_gens_860 = 'https://data.catalyst.coop/pudl/generators_eia860.csv?_stream=on&report_date__gte=2022-01-01&_sort_desc=report_date&_labels=on&_size=max'\n",
    "url_plants_860 = 'https://data.catalyst.coop/pudl/plants_eia860.csv?_stream=on&report_date__gte=2022-01-01&_labels=on&_size=max'\n",
    "url_plants_entitiy ='https://data.catalyst.coop/pudl/plants_entity_eia.csv?_stream=on&_size=max'\n",
    "# os.mkdir('/Users/kamrantehranchi/Local_Documents/pypsa-usa/workflow/data/pudl')\n",
    "PATH = '/Users/kamrantehranchi/Local_Documents/pypsa-usa/workflow/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gens = pd.read_csv(url_gens_860)\n",
    "gens.report_date = pd.to_datetime(gens.report_date)\n",
    "gens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plants = pd.read_csv(url_plants_860)\n",
    "plants.report_date = pd.to_datetime(plants.report_date)\n",
    "plants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plants_entity = pd.read_csv(url_plants_entitiy)\n",
    "plants_entity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gens.to_csv(PATH + '/data/pudl/gens.csv', index=False)\n",
    "plants.to_csv(PATH + '/data/pudl/plants.csv', index=False)\n",
    "plants_entity.to_csv(PATH + '/data/pudl/plants_entity.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge datasets\n",
    "plants_gens = pd.merge(gens, plants, on='plant_id_eia', how='outer', suffixes=('', '_plant'))\n",
    "df = pd.merge(plants_gens, plants_entity, on='plant_id_eia', how='outer', suffixes=('', '_entity'))\n",
    "df.columns = df.columns.str.lower()\n",
    "df.drop(columns=df.columns[df.isnull().all()],inplace=True) #dropping completely empty Columns\n",
    "df.to_csv(PATH + '/data/pudl/plants_gens_entity.csv', index=False)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#count of empty cells\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create bar chart for categorical data\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Set the plot style\n",
    "sns.set_style('whitegrid')\n",
    "\n",
    "# Create a count plot of the categorical variable\n",
    "# sns.countplot(x='energy_source_code_1', data=df)\n",
    "sns.countplot(x='fuel_type_code_pudl', data=df)\n",
    "\n",
    "# Set the title and axis labels\n",
    "plt.title('Category Counts')\n",
    "plt.xlabel('Category')\n",
    "plt.ylabel('Count')\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_columns = ['plant_id_eia', 'plant_name_eia', 'generator_id', 'technology_description', \n",
    "       'capacity_mw', 'state', 'city', 'county', 'operating_date', 'operational_status', 'operational_status_code', \n",
    "       'current_planned_operating_date','original_planned_operating_date', 'latitude', 'longitude', \n",
    "        'summer_capacity_mw', 'winter_capacity_mw', 'zip_code', 'utility_id_eia', \n",
    "        'utility_name_eia']\n",
    "df[query_columns].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "power_genome_sql = '/Users/kamrantehranchi/Downloads/pudl-2.sqlite'\n",
    "import sqlalchemy as sa\n",
    "pudl_engine = sa.create_engine('sqlite:////Users/kamrantehranchi/Downloads/pudl-2.sqlite')#'sqlite:////Users/jakobcourbat/Documents/Research/pudl-v2022.11.30/pudl_data/sqlite/pudl.sqlite')\n",
    "pudl_engine.connect()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gabriels Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "pd.set_option('display.min_rows', None)\n",
    "\n",
    "#we keep only the relevant columns\n",
    "pudl_df = copy.copy(pudl_out.gens_eia860()[['plant_id_eia', 'plant_name_eia', 'generator_id', 'technology_description', \n",
    "       'capacity_mw', 'state', 'city', 'county', 'operating_date', 'operational_status', 'operational_status_code', \n",
    "       'current_planned_operating_date','original_planned_operating_date', 'latitude', 'longitude', \n",
    "        'summer_capacity_mw', 'winter_capacity_mw', 'zip_code', 'plant_id_pudl', 'utility_id_eia', \n",
    "        'utility_id_pudl', 'utility_name_eia']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We only keep the states that are part of the WECC. We choose not to include Texas and treat these manually since there's 2000 of them and only 16 to be matched in ADS dataset\n",
    "#Note: pudl_df doesnt include data for Mexico nor Alberta nor British Columbia\n",
    "\n",
    "pudl_df = pudl_df[pudl_df['state'].isin(['NM', 'AZ', 'CA', 'WA', 'OR', 'ID', 'WY', 'MT', 'UT', 'SD', 'CO', 'NV', 'NE', '0'])]\n",
    "\n",
    "#we delete the duplicated rows\n",
    "pudl_df = pudl_df.drop_duplicates(subset=['plant_id_pudl', 'plant_name_eia', 'generator_id'], keep='first')\n",
    "\n",
    "\n",
    "pudl_df['operating_date'] = pd.to_datetime(pudl_df['operating_date'])\n",
    "\n",
    "pudl_df['plant_name_eia'] = pudl_df['plant_name_eia'].str.replace(\" \", \"\")\n",
    "pudl_df['plant_name_eia'] = pudl_df['plant_name_eia'].apply(lambda x: re.sub(r'[^a-zA-Z0-9]', '', x).lower())\n",
    "\n",
    "pudl_df['technology_description'] = pudl_df['technology_description'].fillna('NA')\n",
    "pudl_df['technology_description'] = pudl_df['technology_description'].apply(lambda x: re.sub(r'[^a-zA-Z0-9]', '', x).lower())\n",
    "\n",
    "print(pudl_df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We make sure that all the rows corresponding to the same plant have their latitude and longitude features properly filled up if at least one of them is properly filled up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pudl_match_gps = {}\n",
    "\n",
    "for _, row in pudl_df.iterrows():\n",
    "    idnum=row['plant_id_eia']\n",
    "    lat = row['latitude']\n",
    "    long = row['longitude']\n",
    "\n",
    "    if (idnum not in pudl_match_gps) and (pd.isna(lat) == False and pd.isna(long) == False):\n",
    "        pudl_match_gps.update({idnum: (lat, long)})\n",
    "\n",
    "for index, row in pudl_df.iterrows():\n",
    "    idnum=row['plant_id_eia']\n",
    "    lat = row['latitude']\n",
    "    long = row['longitude']\n",
    "\n",
    "    if (pd.isna(lat) or pd.isna(long)) and (idnum in pudl_match_gps):\n",
    "        pudl_df.at[index, 'latitude'] = lat\n",
    "        pudl_df.at[index, 'longitude'] = long\n",
    "\n",
    "print(pudl_df[['latitude', 'longitude']])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# initialize ads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ads= pd.read_csv('/Users/jakobcourbat/Documents/Research/2032_ADS/GeneratorList.csv')\n",
    "\n",
    "# we don't include AB, BC, or MX as they don't appear in pudl\n",
    "\n",
    "ads = ads[ads['State'].isin(['NM', 'AZ', 'CA', 'WA', 'OR', 'ID', 'WY', 'MT', 'UT', 'SD', 'CO', 'NV', 'NE', '0', 'TX'])]\n",
    "\n",
    "ads['Long Name'] = ads['Long Name'].astype(str)\n",
    "\n",
    "ads['Commission Date'] = pd.to_datetime(ads['Commission Date'], format='#%Y-%m-%d#')\n",
    "\n",
    "ads['Name'] = ads['Name'].str.replace(\" \", \"\")\n",
    "ads['Name'] = ads['Name'].apply(lambda x: re.sub(r'[^a-zA-Z0-9]', '', x).lower())\n",
    "\n",
    "ads['Long Name'] = ads['Long Name'].str.replace(\" \", \"\")\n",
    "ads['Long Name'] = ads['Long Name'].apply(lambda x: re.sub(r'[^a-zA-Z0-9]', '', x).lower())\n",
    "\n",
    "\n",
    "ads['SubType'] = ads['SubType'].apply(lambda x: re.sub(r'[^a-zA-Z0-9]', '', x).lower())\n",
    "\n",
    "\n",
    "print(ads)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# normalize technology type in SimpleType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pudl_df['SimpleType'] = ''\n",
    "pudl_df.loc[pudl_df['technology_description'].str.contains('hydro'), 'SimpleType'] = 'Hydro'\n",
    "pudl_df.loc[pudl_df['technology_description'].str.contains('solarphotovoltaic'), 'SimpleType'] = 'SolarPV'\n",
    "pudl_df.loc[pudl_df['technology_description'].str.contains('coal'), 'SimpleType'] = 'Coal'\n",
    "pudl_df.loc[pudl_df['technology_description'].str.contains('naturalgas'), 'SimpleType'] = 'Natural Gas'\n",
    "pudl_df.loc[pudl_df['technology_description'].str.contains('wind'), 'SimpleType'] = 'Wind'\n",
    "pudl_df.loc[pudl_df['technology_description'].str.contains('petroleum'), 'SimpleType'] = 'Oil'\n",
    "pudl_df.loc[pudl_df['technology_description'].str.contains('solarthermal'), 'SimpleType'] = 'Solar Thermal'\n",
    "pudl_df.loc[pudl_df['technology_description'].str.contains('waste|landfill'), 'SimpleType'] = 'Biomass'\n",
    "pudl_df.loc[pudl_df['technology_description'].str.contains('allother|flywheel|othergases'), 'SimpleType'] = 'Other'\n",
    "pudl_df.loc[pudl_df['technology_description'] == 'na', 'SimpleType'] = 'Other'\n",
    "pudl_df.loc[pudl_df['technology_description'].str.contains('batteries'), 'SimpleType'] = 'Batteries'\n",
    "pudl_df.loc[pudl_df['technology_description'].str.contains('geothermal'), 'SimpleType'] = 'Geothermal'\n",
    "pudl_df.loc[pudl_df['technology_description'].str.contains('nuclear'), 'SimpleType'] = 'Nuclear'\n",
    "\n",
    "\n",
    "ads['SimpleType'] = ''\n",
    "ads.loc[ads['SubType'].str.contains('battery'), 'SimpleType'] = 'Batteries'\n",
    "ads.loc[ads['SubType'].str.contains('natgas'), 'SimpleType'] = 'Natural Gas'\n",
    "ads.loc[ads['SubType'].str.contains('hydro'), 'SimpleType'] = 'Hydro'\n",
    "ads.loc[ads['SubType'].str.contains('solarthermal'), 'SimpleType'] = 'Solar Thermal'\n",
    "ads.loc[ads['SubType'].str.contains('solarpv'), 'SimpleType'] = 'SolarPV'\n",
    "ads.loc[ads['SubType'].str.contains('nuclear'), 'SimpleType'] = 'nuclear'\n",
    "ads.loc[ads['SubType'].str.contains('coal'), 'SimpleType'] = 'Coal'\n",
    "ads.loc[ads['SubType'].str.contains('onshore'), 'SimpleType'] = 'Wind'\n",
    "ads.loc[ads['SubType'].str.contains('geo'), 'SimpleType'] = 'Geothermal'\n",
    "ads.loc[ads['SubType'].str.contains('bioct|wasteheat|dcintertie|ccabcogen|biocc|ctaero|ccpartsteam|vardevice|unknown|bioice|biost|ctabcogen|dgbtm|motorload|stother'), 'SimpleType'] = 'Other'\n",
    "ads.loc[ads['SubType'] == 'dr', 'SimpleType'] = 'Other'\n",
    "ads.loc[ads['SubType'].str.contains('oil'), 'SimpleType'] = 'Oil'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ads[['SubType', 'SimpleType']])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# merge on IDs from 'Long ID'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "merged_id = pd.DataFrame()\n",
    "i=0\n",
    "for index, ads_row in ads.iterrows():\n",
    "    long_id = ads_row['Long ID']\n",
    "    if isinstance(long_id, str):\n",
    "        long_id_list = re.findall(r'\\d+', long_id)\n",
    "        if len(long_id_list) > 0:\n",
    "            long_id_numbers = max(long_id_list, key = len)\n",
    "            long_id_numbers = pd.Series(long_id_numbers).astype(pd.Int64Dtype()).iloc[0]\n",
    "            if long_id_numbers > 33:\n",
    "                pudl_row = pudl_df[pudl_df['plant_id_eia'] == long_id_numbers]\n",
    "                if len(pudl_row) > 0:\n",
    "                    pudl_row = pudl_row.iloc[0]\n",
    "                    merged_row = pd.concat([ads_row, pudl_row], axis=0)\n",
    "                    merged_id = merged_id.append(merged_row, ignore_index=True)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(merged_id[['GeneratorKey', 'Name', 'plant_name_eia', 'Long ID', 'plant_id_eia', 'generator_id', 'SubType', 'technology_description', 'MaxCap(MW)', 'capacity_mw', 'State', 'state', 'City', 'city', 'County', 'county', 'DevStatus', 'operational_status', 'Commission Date', 'operating_date' ]])\n",
    "merged_id[['GeneratorKey', 'Name', 'plant_name_eia', 'Long ID', 'plant_id_eia', 'generator_id', 'SubType', 'technology_description', 'MaxCap(MW)', \n",
    "        'capacity_mw', 'State', 'state', 'City', 'city', 'County', 'county', 'DevStatus', 'operational_status', 'Commission Date', 'operating_date' ]].to_csv('merged_id.csv', index=False)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# initiate merged_total df that gathers all the matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_total_A = merged_id.copy()\n",
    "merged_total_A['merged_type'] = 'Long_ID'\n",
    "print(merged_total_A)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# merged_exact on exact names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ads_exact = ads[~ads['GeneratorKey'].isin(merged_total_A['GeneratorKey'])].copy()\n",
    "pudl_exact = pudl_df[~pudl_df['plant_id_eia'].isin(merged_total_A['plant_id_eia'])].copy()\n",
    "\n",
    "merged_exact = pd.merge(ads_exact, pudl_exact, left_on=['Name'], right_on=['plant_name_eia'], how='inner')\n",
    "merged_exact = merged_exact.drop_duplicates(subset=['GeneratorKey'])\n",
    "print(merged_exact[['GeneratorKey', 'Name', 'plant_name_eia', 'generator_id', 'Long ID', 'plant_id_eia', 'SubType', 'technology_description', 'MaxCap(MW)', 'capacity_mw', 'State', 'state', 'City', 'city', 'County', 'county', 'DevStatus', 'operational_status', 'Commission Date', 'operating_date' ]])\n",
    "merged_exact[['GeneratorKey', 'Name', 'plant_name_eia', 'generator_id', 'Long ID', 'plant_id_eia', 'SubType', 'technology_description', 'MaxCap(MW)', \n",
    "        'capacity_mw', 'State', 'state', 'City', 'city', 'County', 'county', 'DevStatus', 'operational_status', 'Commission Date', 'operating_date' ]].to_csv('merged_exact.csv', index=False)\n",
    "\n",
    "print('count rows:', len(merged_exact['Name']))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "update merged_total with the new matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_exact['merged_type'] = 'Exact Name'\n",
    "merged_total_B = pd.concat([merged_total_A[['GeneratorKey', 'Name', 'plant_name_eia', 'Long ID', 'plant_id_eia', 'Long Name', 'generator_id', 'MaxCap(MW)', 'capacity_mw', 'SubType', 'technology_description', 'latitude', 'longitude', 'Commission Date', 'operating_date', 'State', 'state', 'County', 'county', 'City', 'city', 'Zipcode', 'zip_code', 'DevStatus', 'operational_status_code', 'Area Name', 'Region Name', 'summer_capacity_mw', 'winter_capacity_mw', 'merged_type']],\n",
    "                           merged_exact[['GeneratorKey', 'Name', 'plant_name_eia', 'Long ID', 'plant_id_eia', 'Long Name', 'generator_id', 'MaxCap(MW)', 'capacity_mw', 'SubType', 'technology_description', 'latitude', 'longitude', 'Commission Date', 'operating_date', 'State', 'state', 'County', 'county', 'City', 'city', 'Zipcode', 'zip_code', 'DevStatus', 'operational_status_code', 'Area Name', 'Region Name', 'summer_capacity_mw', 'winter_capacity_mw', 'merged_type']]], axis = 0)\n",
    "print(merged_total_B)\n",
    "print('count rows:', len(merged_total_B['Name']))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "update merged_total with the new matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "manual_matches_idx= [(17784, 64103),\n",
    "(15266, 60308),\n",
    "(15262, 60307),\n",
    "(5684, 50748),\n",
    "(5698, 57564),\n",
    "(15899, 55514),\n",
    "(15900, 55514),\n",
    "(15901,55200),\n",
    "(15902,55200),\n",
    "(703, 56474),\n",
    "(17272, 55278),\n",
    "(4620, 10649),\n",
    "(2363, 8073),\n",
    "(15905, 8073),\n",
    "(15906, 8073),\n",
    "(15907, 8073),\n",
    "(15908,55295),\n",
    "(15909,55295),\n",
    "(2210,8022),\n",
    "(2211,8022),\n",
    "(2212,8022),\n",
    "(2213,8022),\n",
    "(2214,8022),\n",
    "(2215,8022),\n",
    "(10995,59002),\n",
    "(10996,59002),\n",
    "(10997,59002),\n",
    "(10998,59002),\n",
    "(10999,59002),\n",
    "(6131, 10169),\n",
    "(10559, 58503),\n",
    "(15918, 55662),\n",
    "(15919, 55662),\n",
    "(13986, 57703),\n",
    "(13987, 57703),\n",
    "(13451, 2322),\n",
    "(13452, 2322),\n",
    "(13453, 2322),\n",
    "(13454, 2322),\n",
    "(13455, 2322),\n",
    "(13456, 2322),\n",
    "(13457, 2322),\n",
    "(13458, 2322),\n",
    "(13459, 2322),\n",
    "(13460, 2322),\n",
    "(13461, 2322),\n",
    "(13462, 2322),\n",
    "(14131, 2322),\n",
    "(13710, 2336),\n",
    "(13711, 2336),\n",
    "(6328, 56356),\n",
    "(18423, 7725),\n",
    "(18424, 57015),\n",
    "(15926, 56532),\n",
    "(15927, 56532),\n",
    "(15930, 56102),\n",
    "(15931, 56102),\n",
    "(15426, 52104),\n",
    "(15934, 55333),\n",
    "(15935, 55333),\n",
    "(15936, 55333),\n",
    "(13528, 389),\n",
    "(15941, 389),\n",
    "(15942, 389),\n",
    "(17247, 389),\n",
    "(15943, 55400),\n",
    "(15944, 55400),\n",
    "(18426, 57902),\n",
    "(18427, 58687),\n",
    "(18428, 64505),\n",
    "(9918, 10342),\n",
    "(15950, 56476),\n",
    "(15951, 56476),\n",
    "(15952, 59338),\n",
    "(15953, 59338),\n",
    "(15954, 60768),\n",
    "(15955, 60768),\n",
    "(15956, 59784),\n",
    "(15957, 59784),\n",
    "(15958, 59784),\n",
    "(15959, 59784),\n",
    "(4656, 55810),\n",
    "(4657, 55810),\n",
    "(4658, 55810),\n",
    "(6930, 10034),\n",
    "(17903, 54749),\n",
    "(6953, 55482),\n",
    "(15960, 7999),\n",
    "(15961, 7999),\n",
    "(15962, 55124),\n",
    "(15963, 55124),\n",
    "(7070, 55372),\n",
    "(7072, 55372),\n",
    "(7074, 55372),\n",
    "(13594, 400),\n",
    "(15974, 55518),\n",
    "(15975, 55518),\n",
    "(15976, 55518),\n",
    "(13392, 126),\n",
    "(13393, 126),\n",
    "(18430, 56899),\n",
    "(3463, 8066),\n",
    "(3462, 8066),\n",
    "(3461, 8066),\n",
    "(3391, 8066),\n",
    "(1324, 50494),\n",
    "(7376, 50494),\n",
    "(2168, 550),\n",
    "(18432, 6518),\n",
    "(15985, 55103),\n",
    "(15986, 55103),\n",
    "(15987, 56237),\n",
    "(15988, 56237),\n",
    "(15989, 56237),\n",
    "(15990, 56237)]\n",
    "print(manual_matches_idx[3])\n",
    "\n",
    "merged_manual = pd.DataFrame()\n",
    "\n",
    "for (ads_id, eia_id) in manual_matches_idx:\n",
    "    row_ads = ads.loc[ads['GeneratorKey'] == ads_id]\n",
    "    row_pudl = pudl_df.loc[pudl_df['plant_id_eia'] == eia_id]\n",
    "    merged_row = pd.merge(row_ads, row_pudl, how='inner')\n",
    "    merged_manual = merged_manual.append(merged_row, ignore_index=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(merged_manual[['GeneratorKey', 'Name', 'plant_name_eia', 'plant_id_eia', 'Long Name', 'generator_id', 'MaxCap(MW)', 'capacity_mw', 'SubType', 'technology_description', 'latitude', 'longitude', 'Commission Date', 'operating_date', 'State', 'state', 'County', 'county', 'City', 'city', 'Zipcode', 'zip_code', 'DevStatus', 'operational_status_code', 'Area Name', 'Region Name', 'summer_capacity_mw', 'winter_capacity_mw']])\n",
    "merged_manual[['GeneratorKey', 'Name', 'plant_name_eia', 'plant_id_eia', 'Long Name', 'generator_id', 'MaxCap(MW)', 'capacity_mw', 'SubType', 'technology_description', 'latitude', 'longitude', 'Commission Date', 'operating_date', 'State', 'state', 'County', 'county', 'City', 'city', 'Zipcode', 'zip_code', 'DevStatus', 'operational_status_code', 'Area Name', 'Region Name', 'summer_capacity_mw', 'winter_capacity_mw']].to_csv('merged_manual.csv', index=False)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pudl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
